{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01d382b-3591-47f7-9b49-fccd2188a2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random as rnd\n",
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite #we load the bipartite algorithms to facilitate writing the code\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from Functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e563e7e-4f89-40d8-9783-647a93317c8d",
   "metadata": {},
   "source": [
    "# Checking for statistical relevance\n",
    "\n",
    "## Hypothesis Testing\n",
    "\n",
    "A commonplace task in statistical inferences\n",
    "is calculating the probability of observing a value or something more extreme\n",
    "under an assumed \"null\" model of reality.\n",
    "This is what we commonly call \"hypothesis testing\",\n",
    "and where the oft-misunderstood term \"p-value\" shows up.\n",
    "### Hypothesis testing in coin flips, by simulation\n",
    "\n",
    "As an example, hypothesis testing in coin flips follows this logic:\n",
    "\n",
    "- I observe that 8 out of 10 coin tosses give me heads, giving me a probability of heads $p=0.8$ (a summary statistic).\n",
    "- Under a \"null distribution\" of a fair coin, I simulate the distribution of probability of heads (the summary statistic) that I would get from 10 coin tosses.\n",
    "- Finally, I use that distribution to calculate the probability of observing $p=0.8$ or more extreme.\n",
    "\n",
    "### Hypothesis testing in graphs\n",
    "\n",
    "The same protocol applies when we perform hypothesis testing on graphs.\n",
    "\n",
    "Firstly, we calculate a _summary statistic_ that describes our graph.\n",
    "\n",
    "Secondly, we propose a _null graph model_, and calculate our summary statistic under simulated versions of that null graph model.\n",
    "\n",
    "Thirdly, we look at the probability of observing the summary statistic value that we calculated in step 1 or more extreme, under the assumed graph null model distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89324578-e385-4e0b-8dd8-393ae252519e",
   "metadata": {},
   "source": [
    "## Null models ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e181ef-bb30-4cb5-832b-932bdc9970b9",
   "metadata": {},
   "source": [
    "### Z-Scores and P-values\n",
    "\n",
    "To really asses how different from the random expectation of a null model a given empirical netowrk is, we need to compare out empirical values with the distribution of values in the **random ensemble**.\n",
    "\n",
    "A random ensemble is composed by **$N_{rep}$** random replicates of an empirical network. Dpending on the null model that we use to make the randomizations we will talk about the **ER ensemble**, or **configuration model ensemble**. \n",
    "\n",
    "As we saw before, by comparing our network to the average and the standard deviation of the values in the random ensemble we can determine how statistically significant is the empirical value of the structural feature we are studying."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81c5700-0f95-4483-9223-9add06823448",
   "metadata": {},
   "source": [
    "Let's see the significan. \n",
    "To create a random ensemble we will specify the number of random networks to sample,a nd decide what models to use. We can use more than one, and see how incrementing the model complexity helps us to understand what can be contributing to the empirical structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf36e83-d051-4f44-b2f0-f89c1f9d2ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## read network\n",
    "G = nx.karate_club_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f8849b-3ef2-4993-afc2-cde028fe9e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare storage\n",
    "#determine number of samplings from the random ensemble\n",
    "Nrep = 300  # Replace this with your desired number of repetitions\n",
    "repetitions = range(Nrep + 1)  # Repetition numbers from 0 to Nrep\n",
    "ensembles = [\"ER\", \"CONF\"]  # Ensemble names\n",
    "metrics = [\"Q\", \"C\"]  # Metric names to asses\n",
    "\n",
    "# Create the MultiIndex\n",
    "multi_index = pd.MultiIndex.from_product([repetitions, ensembles], names=[\"Repetition\", \"Ensemble\"])\n",
    "\n",
    "# Create an empty DataFrame with this MultiIndex\n",
    "Value_df = pd.DataFrame(index=multi_index, columns=metrics)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee3e980-87fa-4e19-b534-321cf5cf94a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Value_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70e1e9c-0806-4109-8bc4-686ab54e588e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's start by measuring the metrics in the empirical network\n",
    "#clustering\n",
    "C_emp=nx.average_clustering(G)\n",
    "#modularity: get partition\n",
    "partition = nx.community.louvain_communities(G)\n",
    "# Calculate the modularity\n",
    "Q_emp=nx.community.quality.modularity(G, partition)\n",
    "empirical_values = pd.Series({'Q': Q_emp, 'C': C_emp})\n",
    "print(empirical_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d08a825-2b67-45ab-b7f2-d3c76a51bed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare parameters for null models\n",
    "N=G.number_of_nodes()\n",
    "L=G.number_of_edges()\n",
    "K=pd.Series(dict(G.degree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56698b3c-4b50-46db-b2a1-1498ec5fcf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Noew let's fill the dataframe\n",
    "for rep in range(Nrep+1):\n",
    "    #generate the randomization in first null model\n",
    "    G_ER=nx.gnm_random_graph(N, L)\n",
    "    \n",
    "    #measure quantites:\n",
    "    C=nx.average_clustering(G_ER)\n",
    "    \n",
    "    #modularity: get partition\n",
    "    partition = nx.community.louvain_communities(G_ER)\n",
    "    # Calculate the modularity\n",
    "    Q=nx.community.quality.modularity(G_ER, partition)\n",
    "    \n",
    "    Value_df.loc[(rep,\"ER\"),\"C\"]=C\n",
    "    Value_df.loc[(rep,\"ER\"),\"Q\"]=Q\n",
    "    \n",
    "    #generate the randomization in first null model\n",
    "    G_CF=nx.configuration_model(K, create_using=nx.Graph())\n",
    "    \n",
    "    #measure quantites:\n",
    "    C=nx.average_clustering(G_CF)\n",
    "    \n",
    "    #modularity: get partition\n",
    "    partition = nx.community.louvain_communities(G_CF)\n",
    "    # Calculate the modularity\n",
    "    Q=nx.community.quality.modularity(G_CF, partition)\n",
    "    \n",
    "    Value_df.loc[(rep,\"CONF\"),\"C\"]=C\n",
    "    Value_df.loc[(rep,\"CONF\"),\"Q\"]=Q  \n",
    "    \n",
    "    \n",
    "Value_df.head()   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744a2b94-849e-4c97-833f-5ae8b7ea640f",
   "metadata": {},
   "source": [
    "Now we want to analize how different from the ranfom expectations is my network. For that let's plot the distribution of values in the random ensembles, and compare where lies the empirical value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987437fa-e82d-4785-8bb9-8850763fd7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data to only include the ER model -\n",
    "df_er = Value_df.xs('ER', level='Ensemble')\n",
    "# Filter the data to only include the CONF model -\n",
    "df_conf = Value_df.xs('CONF', level='Ensemble')\n",
    "\n",
    "# Plotting the distributions\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5)) #one plot for each quantity\n",
    "\n",
    "# Plotting Q distribution\n",
    "ax1.hist(df_er['Q'], bins=10, color='lightgreen', edgecolor='black', alpha=0.6)\n",
    "ax1.hist(df_conf['Q'], bins=10, color='orange', edgecolor='black', alpha=0.6)\n",
    "ax1.axvline(Q_emp, color='k', linestyle='--')\n",
    "ax1.set_title('Distribution of Q')\n",
    "ax1.set_xlabel('Q values')\n",
    "ax1.set_ylabel('Frequency')\n",
    "\n",
    "# Plotting C distribution\n",
    "ax2.hist(df_er['C'], bins=10, color='lightgreen', edgecolor='black',alpha=0.6)\n",
    "ax2.hist(df_conf['C'], bins=10, color='orange', edgecolor='black',alpha=0.6)\n",
    "ax2.axvline(C_emp, color='k', linestyle='--')\n",
    "ax2.set_title('Distribution of C')\n",
    "ax2.set_xlabel('C values')\n",
    "ax2.set_ylabel('Frequency')\n",
    "\n",
    "# Display the plots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48b0570-27af-4a2a-8455-1b011230ba56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean and std for each metric and ensemble\n",
    "model_stats = Value_df.groupby('Ensemble').agg(['mean', 'std'])\n",
    "\n",
    "# Initialize z_scores DataFrame\n",
    "z_scores_df = pd.DataFrame(index=['ER', 'CONF'], columns=['Q', 'C'])\n",
    "\n",
    "# Compute z-scores\n",
    "for metric in ['Q', 'C']:\n",
    "    for ensemble in ['ER', 'CONF']:\n",
    "        mean_value = model_stats.loc[ensemble, (metric, 'mean')]\n",
    "        std_value = model_stats.loc[ensemble, (metric, 'std')]\n",
    "        empirical_value = empirical_values[metric]\n",
    "        \n",
    "        # Calculate z-score\n",
    "        z_score = (empirical_value - mean_value) / std_value if std_value != 0 else None\n",
    "        z_scores_df.loc[ensemble, metric] = z_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d869907-ff33-411d-a755-b5ec1417e188",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(z_scores_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c219a2-68b0-4dda-b737-293f4297608e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"><b>Up to you: </b>\n",
    "<h4> Exercise 22</h4>\n",
    "    \n",
    "- 1. compare the different motifs composition in the ER ensemble and the ensemble that keeps the degree sequence of the St. Marks estuary food-web. \n",
    "    Do only 5 repetitions each network (**$N_{rep}=4$**)\n",
    "    \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64a763a-98c7-44eb-ad53-11e0716949c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the edgelist and create the network\n",
    "filename=\"./data/WoL_StMarks/st_marks_Ilist.csv\"\n",
    "Ilist=pd.read_csv(filename, header=None, index_col=None)\n",
    "Ilist.columns=[\"source\",\"target\",\"w\"]\n",
    "FW=nx.from_pandas_edgelist(Ilist, edge_attr=\"w\", create_using=nx.DiGraph)\n",
    "#your code here below\n",
    "# 1. Prepare the number of repetitions and the indexes for the dataframe\n",
    "# 2. Creat the empty dataframe\n",
    "# 3. prepare the parameters for the null models\n",
    "# 4. cuantify the motifs in the empirical network and save them in a series\n",
    "# 5. For each repetition, store the series of motifs indexed by repetition and model type\n",
    "# 6. Once the dataframe is filled, create a figure with two images (one for each model) and plot for each motif the values in the random ensemble\n",
    "# 7. OVerlay the value of the empirical ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9c664b-3408-48c6-9191-933e0f778671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./snippets/ex22a.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e27281-f6a8-442f-a886-bdab047b2a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./snippets/ex22b.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e498fb8-118b-42a6-a7ca-bd5a60675b33",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"><b>Up to you: </b>\n",
    "<h4> Exercise 23</h4>\n",
    "    \n",
    "- 1. Compare the values of nestedness of the Doñana pollination network in the ER, CONF and KSEQ ensembles. \n",
    "    Do only 100 repetitions\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4774dabb-28c5-4255-92bb-249a0e541a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./snippets/ex23a.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ecabb1-4eef-4f23-bab8-3aec9f5b3a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./snippets/ex23b.py\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "net-course",
   "language": "python",
   "name": "net-course"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
