{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83520a5c-a152-4e67-9694-0fd3380816f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #module to work with dataframes\n",
    "import networkx as nx #module to work with networks\n",
    "import numpy as np\n",
    "import scipy as scpy\n",
    "import matplotlib.pyplot as plt\n",
    "from networkx.algorithms import bipartite #we load the bipartite algorithms to facilitate writing the code\n",
    "import random\n",
    "from Functions import *\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb42d0c-7106-4145-aaf2-4491a80c70eb",
   "metadata": {},
   "source": [
    "# Network Structure I: Centrality metrics (node-escale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa0d2cb-c854-4fdd-a942-f0daa29f7c6a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Paths \n",
    "\n",
    "A *path* in a network is a sequence of edges connecting two nodes. Let's start with a very simple, undirected network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f337aa72-7118-4d6e-8315-7e7a8ddf7435",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "G.add_nodes_from([1,2,3,4])\n",
    "G.add_edges_from([(1,2),(2,3),(1,3),(1,4)])\n",
    "nx.draw(G, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fad55c-38cc-452b-92b6-760ca4c00671",
   "metadata": {},
   "source": [
    "In this simple example, we can easily see that there is indeed at least one path that connects nodes 3 and 4. We can verify this with the NetworkX function `nx.has_path(G, start node, end node)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3423f889-f705-45da-91ad-c04e0bae5ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.has_path(G, 3, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754b6b34-b9b0-43bf-8c5f-2c96f4ef2a8d",
   "metadata": {},
   "source": [
    "There can be more than one path between two nodes. Again considering nodes 3 and 4, there are two such \"simple\" paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ca7749-9d69-4515-a319-6d280e06e145",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(nx.all_simple_paths(G, 3, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4159bf60-0dc2-42a6-a24b-0c66f45d496d",
   "metadata": {},
   "source": [
    "We are often most interested in **shortest paths**. In an unweighted network, the shortest path is the one with the fewest edges. We can see that of the two simple paths between nodes 3 and 4, one is shorter than the other. We can get this shortest path with a single NetworkX function `nx.shortest_path(G, start node, end node)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ddd2f3-5cc0-4944-b098-d3a6260c95ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.shortest_path(G, 3, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f392b2d-c64a-408f-9fc5-db10244bb2a5",
   "metadata": {},
   "source": [
    "If you only care about the path length, there's a function for that too: `nx.shortest_path_length(G, start node, end node)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6927e6-e2ba-4426-806d-6b97586120df",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.shortest_path_length(G, 3, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814d30c8-135c-44ac-b2d3-31c95585d7a7",
   "metadata": {},
   "source": [
    "> Note that a path length is defined here by the number of *edges* in the path, not the number of nodes, which implies that for nodes $u$ and $v$.\n",
    ">\n",
    ">    `nx.shortest_path_length(G, u, v) == len(nx.shortest_path(G, u, v)) - 1`\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b637370e-72be-4b64-b15d-f32110df6fcc",
   "metadata": {},
   "source": [
    "You can also obtain the average shortest path length between any pair of nodes in the network with `nx.average_shortest_path_length(G)`, and the maximum shortest path length (or network diameter) with `nx.diameter(G)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a01189-36a5-44a9-8d7a-7bfb3587a219",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.average_shortest_path_length(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5c5531-e5aa-4004-857e-00e4848eea01",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.diameter(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43836c34-fda5-4d47-8bd5-2117334adb0f",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "<div class=\"alert alert-block alert-success\"><b>Up to you: </b>\n",
    "<h4> Exercise 9</h4>\n",
    "Let's work with the network of US air travel routes. The nodes in this graph are airports, represented by their IATA codes.\n",
    "\n",
    "![title](./images/figure6.png)\n",
    "    \n",
    "Two nodes are connected with an edge if there is a scheduled flight directly connecting these two airports. We'll assume this graph to be undirected since a flight in one direction usually means there is a return flight.\n",
    "Thus this graph has edges\n",
    "\n",
    "[('HOM', 'ANC'), ('BGM', 'PHL'), ('BGM', 'IAD'), ...]\n",
    "\n",
    "where ANC is Anchorage, IAD is Washington Dulles, etc.\n",
    "    \n",
    "Load the network of USA flights and analyze it to answer these questions:\n",
    "    \n",
    "- 1) Is there a direct flight between Indianapolis (IND) and Fairbanks, Alaska (FAI)? A direct flight is one with no intermediate stops.\n",
    "- 2) If I wanted to fly from Indianapolis to Fairbanks, Alaska what would be an itinerary with the fewest number of flights?\n",
    "- 3) Can you name these airpotrs (hint: access the \"name\" attribute of the airport node and print it)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35414369-53ed-4e1d-9614-82d90e5f4f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your code here. The network is already loaded\n",
    "G = nx.read_graphml('./data/openflights_usa.graphml.gz')\n",
    "#G.nodes(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954682b9-71ff-430f-984d-f59e4cd3435f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./snippets/ex9.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c946b86-8f79-4864-a342-1b51d3570430",
   "metadata": {},
   "source": [
    "Let's extend these ideas about paths to directed graphs.\n",
    "### Directed paths\n",
    "\n",
    "We know that in a directed graph, an edge from an arbitrary node $u$ to an arbitrary node $v$ does not imply that an edge exists from $v$ to $u$. Since paths must follow edge direction in directed graphs, the same asymmetry applies for paths. Observe that this graph has a path from 1 to 4, but not in the reverse direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa73020-99c9-48fa-b7de-649b5413b597",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = nx.DiGraph()\n",
    "D.add_edges_from([\n",
    "    (1,2),\n",
    "    (2,3),\n",
    "    (3,2), (3,4), (3,5),\n",
    "    (4,2), (4,5), (4,6),\n",
    "    (5,6),\n",
    "    (6,4),\n",
    "])\n",
    "nx.draw(D, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1162aae-38b5-4c3d-a733-0e296511be9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.has_path(D, 1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791ba037-2f2b-42e6-9b0d-c9d06146a83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.has_path(D, 4, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3c83ad-4730-4d4c-ab66-06564fbc13c8",
   "metadata": {},
   "source": [
    "The other NetworkX functions dealing with paths take this asymmetry into account as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2752c89-e486-42d5-9a5b-14eec7de8a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "shortest_path1=nx.shortest_path(D, 2, 5)\n",
    "shortest_path2=nx.shortest_path(D, 5, 2)\n",
    "\n",
    "#lets represent the colroed path. First obtein edges\n",
    "path1_edges = list(zip(shortest_path1, shortest_path1[1:])) \n",
    "path2_edges = list(zip(shortest_path2, shortest_path2[1:])) \n",
    "\n",
    "#plot the graph and the edges on top\n",
    "pos = nx.spring_layout(D)  # Positions for all nodes\n",
    "nx.draw(D, pos, with_labels=True, node_size=500, font_size=10,width=4)\n",
    "nx.draw_networkx_edges(D, pos, edgelist=path1_edges, edge_color='red', width=2) #this needs the position of nodes as an input!! \n",
    "nx.draw_networkx_edges(D, pos, edgelist=path2_edges, edge_color='yellow', width=2) #this needs the position of nodes as an input!! \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ac9a99-cd73-4256-ad0c-06832f1c6f3a",
   "metadata": {},
   "source": [
    "> Note: Since there is no edge from 5 to 3, the shortest path from 5 to 2 cannot simply backtrack the shortest path from 2 to 5 -- it has to go a longer route through nodes 6 and 4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44935f22-4ff6-45bc-8e09-2d168694e5fb",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"><b>Up to you: </b>\n",
    "<h4> Exercise 10</h4>\n",
    "Imagine that after an accident, the 'Suspension-feeding molluscs' have been contaminated with lead. Taking into cosideration the structure of the trophic interactions in the St Marks estudary, aswer the following questions:\n",
    "    \n",
    "- 1 Should we be worried about the well fare of the 'Tonguefish'? \n",
    "- 2 and what about the 'Fish and crustacean-eating birds'?\n",
    "- 3 Should we expect more accumulation of lead in 'Herbivorous ducks' or in 'Fish and crustacean-eating birds', according to their diets? (hint: only consider length of trophic chain)\n",
    "    \n",
    "![title](./images/figure10.jpg)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bb30bd-ec3f-4a7c-9e5a-e62c8be1db76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by loading the network as we did before, and continue with your code\n",
    "filename=\"./data/WoL_StMarks/st_marks_Ilist.csv\"\n",
    "Ilist=pd.read_csv(filename, header=None, index_col=None)\n",
    "Ilist.columns=[\"source\",\"target\",\"w\"]\n",
    "FW=nx.from_pandas_edgelist(Ilist, edge_attr=\"w\", create_using=nx.DiGraph)\n",
    "species=list(FW.nodes())\n",
    "sp0='Suspension-feeding molluscs' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8674d4f5-b23f-4b56-82a0-2f05daef373d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./snippets/ex10.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d082cec-f561-4edf-a8e8-c12c409a9cd7",
   "metadata": {},
   "source": [
    "> If the netowrk is **weighted** (regardless of it being directed or undirected) the shortest path function uses the Dijkstra’s Shortest Path Algorithm automatically, taking the weights into consideration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45977646-47b6-4a8f-9838-f4dc4efc6ee1",
   "metadata": {},
   "source": [
    "## Centrality metrics I\n",
    "\n",
    "Often when looking at a network, we want to find the most \"important\" nodes, for some definition of important. The most basic measure of centrality is the *degree*, or number of links attached to a node. Let's take a look at the network we have loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a9b1cb-9277-40d1-b8ef-6aedb38fc5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = nx.kamada_kawai_layout(G)\n",
    "nx.draw(G,pos,node_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c657c0-8cca-4fb2-9e09-88e6b5c560a3",
   "metadata": {},
   "source": [
    "### Degree centraility\n",
    "\n",
    "Do all airports seem equally easy to access? The degree centrality tell us the **number of neighbours of each node**. In this case, it can be understood as a proxy of how well connected is a given airport. As we saw in lesson 1, we can obtain the **degree centrality** of the nodes in the network using the method `G.degree(node)`.\n",
    "Usually the degree of node $i$ is represented with by $k_i$. We will say that a node has a higher degree centrality if it has a higher degree (i.e. if it has many neighbours). The rationale is **the more connections** a node has -> **the more important** hte node is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818017e6-9303-427c-b8f1-f46088f8bbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "K=pd.Series(dict(G.degree())).sort_values(ascending=False) #let's store the degrees of the nodes in a series, so we can easily access later\n",
    "print(K.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f7fa68-5613-4bc1-b80a-3391b4e80dfc",
   "metadata": {},
   "source": [
    "We can now find which is the best connected airport in the US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e30d98-bfe5-4355-956e-62bf1b8c8a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "airport=K.idxmax()\n",
    "print(\"The most connected airport is the %s with %s direct flights to other destinations\" % (G.nodes[airport][\"name\"],K[airport]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372d5ff8-5b72-45dd-94d1-ffac7bf5d708",
   "metadata": {},
   "source": [
    "#### Degree distributions\n",
    "What is the bigger difference between these two networks?\n",
    "\n",
    "![title](./images/figure7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d93b5e-5e7a-4698-9328-205dc9aec7df",
   "metadata": {},
   "source": [
    "The most basic structural properties of a network are the number of nodes (**N**) and the number of links (**L**). However, how these links are distributed among the nodes (**$K_i$**) has deep implications for other network properties (it is not the same to have all nodes with similar degree, or having a very heterogeneous dostribution). The degree distribution will play a very important role determining other structural metrics in the networks.\n",
    "We can see the **degree distribution** of a network by doing a histogram of the degree series. This will tell us how many nodes with a given number of neighbours are in the network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf0c3d4-4096-4b06-ad25-1e95767b50d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#do histogram of degree. Fixed bin width to 1.\n",
    "bins = np.arange(K.min(), K.max() + 2, 1)#fix width of bin to 1\n",
    "hist, bin_edges = np.histogram(K, bins=bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92aeecc1-f8ec-41e8-abf5-faf0d273adf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's plot the histogram to see ho is K distributed\n",
    "plt.bar(bin_edges[:-1],hist)\n",
    "#plt.plot(bin_edges[:-1], hist, 'o',color=\"k\",alpha=0.3)\n",
    "#plt.yscale('log')\n",
    "#plt.xscale('log')\n",
    "plt.title(\"Degree distribution of Airports in USA\")\n",
    "plt.xlabel(\"Degree of node (K)\")\n",
    "plt.ylabel(\"Number of nodes with degree K\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081ec522-41da-41e2-8e55-b6802c720912",
   "metadata": {},
   "source": [
    "And we can also obtain simple statistics from it, like the mean degree, and its standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf4d14c-8c16-459b-98d1-8d771a95c1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_mean=K.mean()\n",
    "K_std=K.std()\n",
    "\n",
    "print(\"The average number of direct flights from an US airport is %.2f +- %.2f\"  % (K_mean,K_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00371bba-1d9a-4ef2-a4bd-7579c98000cc",
   "metadata": {},
   "source": [
    "> Note: In these **long tailed distributions** the verage value is not representative of anything, as the standard distribution is larger than the mean!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa5cd26-66a4-4f86-9f88-5f1dacbab77d",
   "metadata": {},
   "source": [
    "There has been a lot of debate regarding the form of the degree distribution ($P(K)$) in real networks. The best practice to determine which function fits better the $P(K)$) is to use the **cumulative degree distribution** (i.e. how many nodes with degree $K$ or below are in the network) because it is less noisi. \n",
    "Let's see how we can do this.\n",
    "\n",
    "Let's compare the degree distribution of the empirical network with a random one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eda6f67-0e00-4568-9876-275049009079",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare with a random network:\n",
    "#obtain N, L and genetare random network\n",
    "N=G.number_of_nodes()\n",
    "L=G.number_of_edges()\n",
    "Grnd=nx.gnm_random_graph(N,L,directed=False)\n",
    "\n",
    "posr = nx.kamada_kawai_layout(Grnd)\n",
    "nx.draw(Grnd,posr,node_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f9b65b-cac8-4917-8417-5e325d7da3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get degree of nodes in the network\n",
    "Krnd=pd.Series(dict(Grnd.degree())).sort_values(ascending=False) \n",
    "#do histogram of degree. Fixed bin width to 1.\n",
    "binsr = np.arange(Krnd.min(), Krnd.max() + 2, 1)#fix width of bin to 1\n",
    "histr, bin_edgesr = np.histogram(Krnd, bins=binsr)\n",
    "#let's plot the histogram to see ho is K distributed\n",
    "plt.bar(bin_edgesr[:-1],histr)\n",
    "plt.title(\"Degree distribution\")\n",
    "plt.xlabel(\"Degree of node (K)\")\n",
    "plt.ylabel(\"Number of nodes with degree K\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9888793-7b8a-4d90-8408-de3127b56d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the cumulative sum, but in reverse order to count values greater than or equal\n",
    "cumulative_hist = np.cumsum(hist[::-1])[::-1]\n",
    "cumulative_histr = np.cumsum(histr[::-1])[::-1]\n",
    "#plot\n",
    "plt.plot(bin_edges[:-1], cumulative_hist, 'o',color=\"k\",alpha=0.3)\n",
    "plt.plot(bin_edgesr[:-1], cumulative_histr, 'o',color=\"r\",alpha=0.3)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.title(\"Cumulative degree distribution of USA airports (black) and random (red)\")\n",
    "plt.xlabel(\"Degree of node (K)\")\n",
    "plt.ylabel(\"Number of nodes with degree K or more\") #\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e81426-5d86-4f1f-bf5c-fb0b229f4f64",
   "metadata": {},
   "source": [
    "#### Generalizing \"neighbors\" to arbitrarily-sized graphs\n",
    "\n",
    "The concept of neighbors is simple and appealing,\n",
    "but it leaves us with a slight point of dissatisfaction:\n",
    "it is difficult to compare graphs of different sizes.\n",
    "Is a node more important solely because it has more neighbors?\n",
    "What if it were situated in an extremely large graph?\n",
    "Would we not expect it to have more neighbors?\n",
    "\n",
    "As such, we need a normalization factor.\n",
    "One reasonable one, in fact, is\n",
    "_the number of nodes that a given node could **possibly** be connected to._\n",
    "By taking the ratio of the number of neighbors a node has\n",
    "to the number of neighbors it could possibly have,\n",
    "we get the **degree centrality** metric.\n",
    "\n",
    "Formally defined, the degree centrality of a node (let's call it $d$)\n",
    "is the number of neighbors that a node has (let's call it $k$, its degree)\n",
    "divided by the number of neighbors it could _possibly_ have (let's call it $N$, all nodes):\n",
    "\n",
    "$$d = \\frac{k}{N}$$\n",
    "\n",
    "NetworkX provides a function for us to calculate **degree centrality** conveniently:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5d0943-0963-4ee3-ab22-985708892567",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.Series(nx.degree_centrality(G)).sort_values(ascending=False)\n",
    "print(d.head())\n",
    "d.hist()\n",
    "plt.xlabel(\"Degree centrality of node (d)\")\n",
    "plt.ylabel(\"Number of nodes with degree centrality d\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9007dd-d5a0-4aee-b9e0-f20f82df869d",
   "metadata": {},
   "source": [
    "> Note: degree centrality is usefull to determine how \"central\" a node is **across** different networks, since **it does not make sense to compare the raw number of neighbours across networks with different size**!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6144cb13-6953-45d8-82f7-6662761a87ce",
   "metadata": {},
   "source": [
    "### Degree centraility in bipartite networks\n",
    "When we are working with bipartite networks, we should use the algorithms included in `nx.bipartite` and not those of the unipartite networks! \n",
    "\n",
    "Lets see some examples\n",
    "In the bipartite case, the maximum possible degree of a node in a bipartite node set is the number of nodes in the opposite node set. The degree centrality for a node $u$ in the bipartite set $U$ with $n$ nodes that is connected to nodes in the bipartite set $V$ with $m$ nodes is\n",
    "$$d_u=\\frac{k_u}{m}$$, for $u\\in U$, and for a node $v$ nodes in set $V$ is $$d_v=\\frac{k_v}{n}$$, for $v\\in V$,\n",
    "\n",
    "where $k_v$ is the degree of node v."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ac18a1-4906-4df4-9170-800a0e7d4c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the crime network\n",
    "Bcrime = load_crime_network()\n",
    "person_nodes = {n for n, d in Bcrime.nodes(data=True) if d[\"bipartite\"] == 'person'}\n",
    "crime_nodes = set(Bcrime) - person_nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23d6cb0-11ad-4f4c-a926-04c75d8b0da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DC=pd.Series(dict(nx.degree_centrality(Bcrime))).sort_values(ascending=False) #using the unipartite function not paying attention to the bipartite sets\n",
    "DC.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3186d048-9489-4735-a35c-221d90d24f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DC_bipart=pd.Series(dict(bipartite.degree_centrality(Bcrime,person_nodes))).sort_values(ascending=False)#using the bipartite function!!\n",
    "DC_bipart.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4375513-2b75-4ff3-adb3-da8c7f53235e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"><b>Up to you: </b>\n",
    "<h3> Exercise 11</h3>\n",
    "Load the  two seed-dispersal networks of and answer the following questions:\n",
    "\n",
    "- 1. What is the **degree** of the bird named 'Loxigilla portoricensis ' in the two networks? (the space in the name is not an error)\n",
    "- 2. What is its **degree centrality** in the two networks?\n",
    "- 3. In which network is more \"central\"?\n",
    "- 4. Obtain the degree distribution of the animals in the network\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7227647-cc01-4584-a89a-c24c1260e370",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hints:\n",
    "#load first network\n",
    "a0='Loxigilla portoricensis '\n",
    "filename=\"./data/WoL_fugivory/1.csv\" \n",
    "Idf1=pd.read_csv(filename, header=0, index_col=0)\n",
    "B1 = nx.Graph()\n",
    "# Add producers (rows) and consumers (columns) as nodes\n",
    "plants1 = Idf1.index\n",
    "animals1 = Idf1.columns\n",
    "B1.add_nodes_from(plants1, bipartite=\"plant\")  # Set for producers\n",
    "B1.add_nodes_from(animals1, bipartite=\"animal\")  # Set for consumers\n",
    "    # Add edges for non-zero interactions, we can also use the matrix directly\n",
    "for plant in plants1:\n",
    "    for animal in animals1:\n",
    "        if Idf1.loc[plant, animal] != 0:\n",
    "            B1.add_edge(plant, animal)\n",
    "#continue your code below\n",
    "# - load the second network\n",
    "# - get the degree of the bird in each network\n",
    "# - calculate the degree centrality of the nodes as we just saw and get that of the animal with D1.loc[a0] (this selects the element a0 from the series D1)\n",
    "# - Obtain the series of degree of each node, build the cumulative histogram for each network and plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f7a082-2eab-4693-bccd-fbaa8c92c281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./snippets/ex11.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d3fea1-c08d-4598-8d1d-feb9a40555af",
   "metadata": {},
   "source": [
    "### Betweenness centrality\n",
    "We just saw how a node that is \"important\" could be so because it is connected to many other nodes. The rationale is that it exersts a lot of **direcet** influence on their neighbours.\n",
    "\n",
    "Paths give us an alternative definition. If we imagine that we have to pass a message on a graph from one node to another,\n",
    "then there may be \"bottleneck\" nodes for which if they are removed,then messages have a harder time flowing through the graph.\n",
    "\n",
    "One metric that measures this form of importance is the **betweenness centrality** metric.\n",
    "On a graph through which a generic \"message\" is flowing, a node with a high betweenness centrality\n",
    "is one that has a high proportion of shortest paths flowing through it.\n",
    "In other words, it behaves like a _bottleneck_.\n",
    "In some cases you can be more interested in knowing the extent to which a node lies on paths between other nodes. For example, the airport that is most used as an intermediate stop between other destinations. \n",
    "\n",
    "NetworkX provides a `.betweenness centrality` function that behaves consistently with the `.degree centrality` function, in that it returns a mapping from node to metric.\n",
    "To claculate the betweeness centrality we do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f767bcf-74b2-4a72-a632-5ff96eec6bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "betweenness = pd.Series(nx.centrality.betweenness_centrality(G)).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc5f711-7dff-43e0-8341-c552fbfbcc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(betweenness) # the betwennes centrality of airports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c47ec4a-e6fc-4761-a49b-b43b8f6dfde5",
   "metadata": {},
   "source": [
    "### Closeness centrality\n",
    "\n",
    "Also based in te idea of traveling trough the graph, Closeness centrality indicates how close a node is to all other nodes in the network. It is calculated as the average of the shortest path length from the node to every other node in the network. In the airport network it means the airport that is best connected to the rest of the airports (in fewer jumps).\n",
    "\n",
    "> Beware, as it can be infinite if there are not connected nodes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7786616b-ea7b-41c7-a924-5335cb6d4b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "closenness = pd.Series(nx.centrality.closeness_centrality(G)).sort_values(ascending=False)\n",
    "print(closenness)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3d8fc8-fb1f-4f90-80e0-0140072b7dfb",
   "metadata": {},
   "source": [
    "You probably realized that the centrality metrics of nodes do **NOT** neccesarily coincide, that is, one can have many direct lfights to other destinations, but not be an airport where people change flights, or not be very close to all other airports. Let's see it in our Airports network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722a4561-e107-47de-8239-835dfbf6349b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Airports=list(G.nodes) # Colored by degree\n",
    "nx.draw(G,pos,node_color=d[Airports],node_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac95be2-f61b-4ef8-9ea8-90a2b42e5627",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(G,pos,node_color=betweenness[Airports],node_size=50) # colored by betwenness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dec69e-aefd-4279-b829-c21bcd124501",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(G,pos,node_color=closenness[Airports],node_size=50)#colored by closeness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca70ffc5-5df6-4c34-90e9-413d601e5aae",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"><b>Up to you: </b>\n",
    "<h3> Exercise 12</h3>\n",
    "Now that we have seen the differnt ways in what nodes can be central, work with the airport network and answer these questions:\n",
    "    \n",
    "- 1. What is the airport with more direct flights?\n",
    "- 2.  Imagine you are a CEO of an USA corporation and take frequent flights to many different places across the states. In what city do you ask the company to rent you a flat? \n",
    "- 3.  Your corporation (that aims expand as restaurants in airports) ask you the airport where they should put the first restaurant (hint: you don't have access to the actual number of people travelling, only to the airports network)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10202d8-272a-45a7-8410-1b9a12d3f758",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba56bfb9-97ec-413c-a2ea-6d722b21bade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./snippets/ex12.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac11cbb-d046-4ca7-ac25-e21b19c1d950",
   "metadata": {},
   "source": [
    "## Consecuences of the structure (testing Robustness)\n",
    "\n",
    "Another way to think about the relative \"importance\" of nodes in a network is to measure how much it would damage the network structure if particular nodes were to be removed. In real life, node removal might be a person moving away and out of a social network, someone changing jobs and being removed from an email network, internet routers being attacked/overloaded and going down, etc.\n",
    "\n",
    "Broadly, we consider two types of network damage: **random failure** and **targeted attack**. In a random failure, nodes are chosen randomly for removal. In a targeted attack, we will remove nodes based on some criterion, for example, removing nodes in decreasing order of their degree centrality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5480690-5ce6-4edf-a1c0-0cb08030dcd7",
   "metadata": {},
   "source": [
    "### Random failure\n",
    "\n",
    "Whenever we're going to engage in a distructive process, we want to make a copy of the network graph to attack so that we can easily get back to the original state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf39fd9-9d7f-45ac-a328-fb54bb5157bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = G.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db2ed2e-c177-40ff-888e-66ecaa15054a",
   "metadata": {},
   "source": [
    "To simulate random failure, we randomly choose some node names and remove them from the graph. We can use `random.sample` to remove more than one node at at time. Note that we need to make a `list` of node names from which to randomly sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df91ae96-0f4d-4270-918a-64c015838cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_to_remove = random.sample(list(C.nodes), 5) #lets attack 5 airports at a time\n",
    "print(nodes_to_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d3d6db-3466-43cd-8ae9-ecec740ba235",
   "metadata": {},
   "source": [
    "You can remove nodes from the network with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785a4e67-d3cd-41c8-b943-fbc8101ebbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(C.number_of_nodes())\n",
    "C.remove_nodes_from(nodes_to_remove)\n",
    "print(C.number_of_nodes())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b2bb31-f0ef-4583-9cd8-f101bcac2bd3",
   "metadata": {},
   "source": [
    "The full simulation is going to work like this, beginning from a fresh copy of the network:\n",
    "\n",
    "1. Measure size of the network core (number of nodes in the largest component) as compared to the original network size\n",
    "2. Select 5 nodes at random and remove them\n",
    "3. Repeat until there are less than 5 nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0384e6f5-ec4e-4b0d-8a4f-88db06c132de",
   "metadata": {},
   "source": [
    "We can then use `range` to generate a sequence of the total number of nodes removed at each step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6944783-d174-468f-a2aa-6bcea29c5114",
   "metadata": {},
   "outputs": [],
   "source": [
    "M=1 #this was is easier to change this value later\n",
    "num_nodes_removed = range(0, G.number_of_nodes(), M) # we will remove nodes 5 at a time\n",
    "num_nodes_removed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4044e7-f921-4eb1-859c-1b0dd35578a6",
   "metadata": {},
   "source": [
    "Generate a random ordering of the nodes, that we will attack 5 at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f97aaa-561a-4bc3-a9f1-197a0f3162b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = list(G.nodes())\n",
    "random_node_ordering=random.sample(nodes, len(nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18af9b5e-db8c-4fb9-a5d9-fb417fa353d6",
   "metadata": {},
   "source": [
    "The loop is fairly simple. At each step, we need to record the fraction of remaining nodes in the core."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4cb8e3-cfd3-4a60-9483-a46e8222a5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = G.number_of_nodes()\n",
    "C = G.copy()\n",
    "random_attack_core_proportions = []\n",
    "i=0\n",
    "for nodes_removed in num_nodes_removed:\n",
    "    # Measure the relative size of the network core\n",
    "    core = max(nx.connected_components(C), key=len) # we will see more about this later, for now consider is a measure of the integrity of the network\n",
    "    core_proportion = len(core) / N\n",
    "    random_attack_core_proportions.append(core_proportion) # we are creating a list with the proportion of nodes in the largest component\n",
    "\n",
    "    # If there are more than M nodes, select M nodes at random and remove them\n",
    "    if C.number_of_nodes() > M:\n",
    "        nodes_to_remove = random_node_ordering[i:i+M]\n",
    "        C.remove_nodes_from(nodes_to_remove)\n",
    "        i += M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d7221c-a636-41eb-99f2-bc2a67c18ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Random failure')\n",
    "plt.xlabel('Number of nodes removed')\n",
    "plt.ylabel('Proportion of nodes in core')\n",
    "plt.plot(num_nodes_removed, random_attack_core_proportions, marker='o') #we plot the proportion of nodes in the giant component vs the number of removed nodes\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e3c86d-609f-464a-95ca-b15b7083b1e0",
   "metadata": {},
   "source": [
    "#### Targeted attack\n",
    "\n",
    "Simulating a targeted attack is similar, except that instead of choosing randomly, we will select the M most central nodes (according to differentcentrality metrics) at each step. To accomplish this we want something like the `max` function used earler to get the most central node, but able to get the top M nodes. We can use Python's `sorted` function in a similar way to `max` to first sort the nodes by centrality in descending, or reverse, order. Once sorted by degree, we take the first M nodes in the list:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7f793d-1c2d-43c5-b679-55b9582ee19b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"><b>Up to you: </b>\n",
    "<h3> Exercise 13 </h3>\n",
    "Now try differnt orderings when attacking the airports. If you wanted to isolate the country as fast as possible which technique would you use?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a404ea4-0803-454e-881f-7f41cc4870c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hint: Reuse the  loop from the random attack, but instead of using a list of nodes in random order, use a list of nodes ordered by some property\n",
    "# 1-copy the loop\n",
    "# 2-substitute the \"random_node_ordering\" list by a list of nodes orderd by a centrality metric store them \n",
    "# in a series like we did before: closenness = pd.Series(nx.centrality.closeness_centrality(G)).sort_values(ascending=False), and retreve the index with \n",
    "# Clos=list(closeness.index)\n",
    "# 3-To obtain the list of nodes sorted by a given centrality metric\n",
    "# 4-Instead of storing the results in the list \"random_attack_core_proportions\" create a new one \"target_attack_core_proportions_METRIC\" = [] and append the results there\n",
    "# 5-Compare the different attack methods by plotting all the proportion of remaining nodes in the same graph like this\n",
    "\n",
    "plt.title('Random failure vs. targeted attack')\n",
    "plt.xlabel('Number of nodes removed')\n",
    "plt.ylabel('Proportion of nodes in core')\n",
    "plt.plot(num_nodes_removed, random_attack_core_proportions, marker='o', label='Failures')\n",
    "plt.plot(num_nodes_removed, B_attack_core_proportions, marker='^', label='B Attacks')\n",
    "#.... (you can test all the metrics you want, but dont forget to run a loop, and store the values in a different attack)\n",
    "plt.legend()\n",
    "#your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923d37b1-7aad-45e9-b989-38dfd9af55e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./snippets/ex13.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12537970-e805-44f8-b934-d34e88fcc126",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Other centrality metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78eca9c-be64-44ba-bb8f-b0b5780aed10",
   "metadata": {
    "tags": []
   },
   "source": [
    "### K_core decomposition\n",
    "The k-core of a graph is a maximal subgraph in which every vertex has at least degree kk.\n",
    "It’s a way to iteratively remove nodes with degree less than kk, resulting in progressively smaller subgraphs.\n",
    "k-core decomposition identifies these subgraphs for varying values of kk. The larger the kk, the more \"central\" or \"core\" the remaining nodes are considered to be in the graph's structure.\n",
    "\n",
    "For example, a 2-core would be a subgraph where all nodes have at least degree 2, meaning each node is connected to at least two other nodes.\n",
    "The process continues by removing nodes with degrees less than kk until the condition is met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc228767-6957-4f27-9efa-a13feedbbd82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "K10=nx.k_core(G,k=10)\n",
    "nx.draw(K10,node_color=d[list(K10.nodes)],node_size=50)#colored by closeness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080f6158-5dfe-414e-903f-cf8084cfc39e",
   "metadata": {
    "tags": []
   },
   "source": [
    "you can retrieve the k-core of each node with the function `nx.core_number(G)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6d033f-7beb-43f9-a814-8fd4eae60aa5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Kcore=pd.Series(dict(nx.core_number(G)))\n",
    "Kcore.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd35a1f-1c11-4962-8376-bcfdef55221f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Page Rank\n",
    "\n",
    "PageRank computes a ranking of the nodes in the graph G based on the structure of the incoming links. It was originally designed as an algorithm to rank web pages.\n",
    "However, it can also be used to identify the species that \"move\" more biomass trough a network, or in general, the node that is most used when trasnporting information trough the graph. Since this is only interesting in **directed graphs** let's use one of our directed networks. It has been used, for example, to find what are the nodes that are pointing to the more \"important\" nodes, in order to find the species that can cause more harm when they disapear from the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea77630-dd36-42a3-abf1-b436da2bf5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by loading the network as we did before\n",
    "filename=\"./data/WoL_StMarks/st_marks_Ilist.csv\"\n",
    "Ilist=pd.read_csv(filename, header=None, index_col=None)\n",
    "Ilist.columns=[\"source\",\"target\",\"w\"]\n",
    "FW=nx.from_pandas_edgelist(Ilist, edge_attr=\"w\", create_using=nx.DiGraph)\n",
    "TL=nx.centrality.trophic_levels(FW)#get trophic level of node\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118aaa62-6cec-419a-aa8d-f59950865a2d",
   "metadata": {},
   "source": [
    "Now let's compute the Page rank:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bdb349-f5be-4e3a-9103-5b1ba5bf60f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "PR = pd.Series(nx.pagerank(FW.reverse(), alpha=0.9)) #alpha is damping parameter for PageRank, default=0.85.\n",
    "#PR.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3d8b62-f421-42b1-b9fd-0e11c6c5bc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FW.remove_node(base_node)\n",
    "species=list(FW.nodes)\n",
    "pos= nx.shell_layout(FW)\n",
    "TL=nx.centrality.trophic_levels(FW)\n",
    "# Modify the y-coordinate based on the trophic level\n",
    "for node in pos:\n",
    "    pos[node] = (pos[node][0], TL[node])  # Set the y-position as the trophic level\n",
    "\n",
    "nx.draw(FW, pos, node_color=PR[species], with_labels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74753484-4411-48b8-8fa2-89d98af90698",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3536b7d8-b845-4f65-afe7-f040d7785b4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce653df-72f0-431f-9582-04be18d1694e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2c5433-1849-4399-9815-c9f44797116f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb2ef5b-35ba-48ed-9f1d-2fac19f4edd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "net-course",
   "language": "python",
   "name": "net-course"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
