{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2b0573-f8a3-49d0-8764-be4e974cbc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #module to work with dataframes\n",
    "import networkx as nx #module to work with networks\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from Functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455c5bda-c4d4-4873-b424-b3d722a0877a",
   "metadata": {},
   "source": [
    "# Dynamics on networks and dynamics of networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7c7a02-8c43-49e4-8df0-007f60790839",
   "metadata": {},
   "source": [
    "# Dynamics of networks: Temporal networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6395ec98-f9d9-4bf8-929d-a154e9229067",
   "metadata": {},
   "source": [
    "To get some practice with temporal networks we will analyze the co-occurrence network of the characters in the Game of Thrones books. Here, two characters are considered to co-occur if their names appear in the vicinity of 15 words from one another in the books. The edge weight corresponds to the number of interactions. . The dataset is publicly avaiable for the 5 books at https://github.com/mathbeveridge/asoiaf. Let's take a look at it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23680d98-0760-419f-807b-f6b34237d6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "books = load_game_of_thrones_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7feff9-ee6a-4516-a815-3e826a9f2070",
   "metadata": {},
   "outputs": [],
   "source": [
    "books"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137b08be-c999-4223-86a9-220694983dc2",
   "metadata": {},
   "source": [
    "As you can see this data easily translates to a network problem. Now it's time to create a network.\n",
    "We create a graph for each book. It's possible to create one `MultiGraph`(Graph with multiple edges between nodes) instead of 5 graphs, but it is easier to analyse and manipulate individual `Graph` objects rather than a `MultiGraph`. We can consider this a sort of **temporal network**, where each book is a different snapshot at the relationshiops between characters. As we have  books we will have 5 snapshots. While there are librars that allow you to better work with temporal networks, you can still do that by combining your analysis of the 5 networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164a7f44-127e-486a-881f-91d5ac04e83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create a list of graph objects using\n",
    "# nx.from_pandas_edgelist and specifying\n",
    "# the edge attributes.\n",
    "\n",
    "graphs = [nx.from_pandas_edgelist(\n",
    "          books[books.book==i],\n",
    "          source='Source', target='Target',\n",
    "          edge_attr=['weight', 'weight_inv'])\n",
    "          for i in range(1, 6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15718a04-f571-49b3-9ff0-e6b2c3e7c966",
   "metadata": {},
   "outputs": [],
   "source": [
    "#what is contained in the list? # a list of 5 networks\n",
    "graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6b9827-a78e-40b0-aa4d-fa6b15826afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Graph object associated with the first book.\n",
    "graphs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537cd5b3-47fd-42be-a902-210b4c0b283b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To access the relationship edges in the graph use(data=True)\n",
    "relationships = list(graphs[0].edges(data=True)) #creates a list of all the edges with their attributes (only weight, as \"book\" we took it out when we did 5 networks!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176f3c45-0241-4b30-974a-270eb1f852da",
   "metadata": {},
   "outputs": [],
   "source": [
    "relationships[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75960c82-a341-4fe8-94ec-11c6aba2c847",
   "metadata": {},
   "source": [
    "## Finding the most important node i.e character in these networks.\n",
    "\n",
    "Let's use our network analysis knowledge to see what we can learn of these Graphs that we have just created, and their changes trough time.\n",
    "\n",
    "Is it Jon Snow, Tyrion, Daenerys, or someone else the most central character? Let's see! Network Science offers us many different metrics to measure the importance of a node in a network as we saw in lesson 2A. Note that there is no \"correct\" way of calculating the most important node in a network, every metric has a different meaning.\n",
    "\n",
    "First, let's measure the importance of a node in a network by looking at the number of neighbors it has, that is, the number of nodes it is connected to. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cf0035-ac7b-41f4-8b8f-f6da6a2cf243",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"><b>Up to you:</b>\n",
    "<h4> Exercise 24</h4>\n",
    "    \n",
    "Considering that you seek to compare the importance of same nodes across different networks (as the network will be changing in time) in term of their **number of neighbours**, what metric should you use, **degree cenrtality** or **node degree**?\n",
    "    \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891916af-9402-41d4-8d5e-6cf157cae041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no need to code, just think and remember!\n",
    "# %load ./snippets/ex24.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb382113-0dbd-4b6e-847e-e1807d5e377a",
   "metadata": {},
   "source": [
    "Using this measure, let's extract the top ten important characters from the first book (`graphs[0]`) and the fifth book (`graphs[4]`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb91167b-b0f5-4f3b-b2bb-af4203f74c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the in-built degree_centrality method\n",
    "deg_cen_book1 = pd.Series(dict(nx.degree_centrality(graphs[0]))).sort_values(ascending=False)\n",
    "deg_cen_book5 = pd.Series(dict(nx.degree_centrality(graphs[4]))).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19eb5ea5-d633-441b-aff9-714699d94339",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(deg_cen_book1.head(10))\n",
    "print(deg_cen_book5.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273aa192-4184-4bd4-8ee1-6825f09e467e",
   "metadata": {},
   "source": [
    "## Evolution of importance of characters over the books\n",
    "\n",
    "According to degree centrality the most important character in the first book is Eddard Stark but he is not even in the top 10 of the fifth book. \n",
    "The importance changes over the course of five books, because you know stuff happens ;)\n",
    "\n",
    "How can we study changes in characters cenrtality? For example looking at the evolution of degree centrality of some relevant charactesr like Eddard Stark, Jon Snow, or Tyrion which showed up in the top 10 of degree centrality in first book.\n",
    "\n",
    "For that, we need to create a dataframe that contains: the character, the book, and the character importance in that book. We will create a dataframe with character columns and index as books, where every entry is the degree centrality of the character in that particular book and plot the evolution of the degree centrality of Eddard Stark, Jon Snow and Tyrion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc904081-d8ab-420a-9f30-8619493bf825",
   "metadata": {},
   "outputs": [],
   "source": [
    "evolK = [nx.degree_centrality(graph) for graph in graphs] #creates a list containing the dictionaries of degree centralities of the charactesr\n",
    "evolK_df = pd.DataFrame.from_records(evolK).fillna(0) #create a dataframe using book as index, characters as columns, and centrality as values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfe2f41-e960-4af8-a3a0-db810c33ec61",
   "metadata": {},
   "outputs": [],
   "source": [
    "evolK_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701e6ed8-bed9-454c-ac1a-57616f87a2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters=['Eddard-Stark','Tyrion-Lannister','Jon-Snow']#'Daenerys-Targaryen','Arya-Stark'\n",
    "evolK_df[characters].plot(style='o-')\n",
    "plt.ylabel(\"Character centrality\")\n",
    "plt.xlabel(\"Book\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbf87e0-6338-45d7-8fda-97ea7aacf110",
   "metadata": {},
   "source": [
    "We can see that the importance of Eddard Stark in the network dies off and with Jon Snow there is a drop in the fourth book but a sudden rise in the fifth book"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59ac97c-02ce-4a23-bdb5-06ebe52719d1",
   "metadata": {},
   "source": [
    "## Betweeness centrality\n",
    "\n",
    "Let's do this for Betweeness centrality and check if this makes any difference. As different centrality method use different measures underneath, they find nodes which are important in the network. A centrality method like Betweeness centrality finds nodes which are structurally important to the network, which binds the network together and densely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cb95db-06de-4f3e-8651-223ad401a635",
   "metadata": {},
   "outputs": [],
   "source": [
    "evolB = [nx.betweenness_centrality(graph, weight=\"weight_inv\") for graph in graphs]\n",
    "evolB_df = pd.DataFrame.from_records(evolB).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca55fa6-660b-424e-8b15-87d67a1b135a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's find the characters that are more relevant por joining many plots:\n",
    "characters=evolB_df.sum().sort_values(ascending=False).index.to_list()[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905effc6-faf6-45a0-aa5d-fe1f331cdd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "evolB_df[characters].plot(style='o-')\n",
    "plt.ylabel(\"Character betweennes\")\n",
    "plt.xlabel(\"Book\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295284bb-2c41-4d25-8481-b1a6c65a13a9",
   "metadata": {},
   "source": [
    "## Evolution of Roles over time\n",
    "We can now determine characters that are incresing or decreasing in importance in the plot of the books!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85def27e-b6ed-4912-ae28-faadcd78ed14",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_characters=evolK_df.columns\n",
    "evolK_df.reset_index(names=\"book\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3edfa1-2137-4cab-b66b-a6387c627784",
   "metadata": {},
   "outputs": [],
   "source": [
    "Centrality_evol=evolK_df[all_characters].corrwith(evolK_df[\"book\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6bd690-1989-442e-b27d-aa231947c626",
   "metadata": {},
   "outputs": [],
   "source": [
    "loosers=Centrality_evol.sort_values(ascending=True).index.to_list()[0:3]\n",
    "winners=Centrality_evol.sort_values(ascending=False).index.to_list()[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9d777a-f34e-4220-94f1-d4afce232cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Centrality_evol.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9139db4e-43ff-452e-b48e-d9a823435081",
   "metadata": {},
   "outputs": [],
   "source": [
    "evolK_df[loosers + winners ].plot(style='o-')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7679b48d-5bf6-4c79-8849-41fb09f5ca69",
   "metadata": {},
   "source": [
    "## Node and Link constancy\n",
    "\n",
    "In temporal networks we can also see if nodes and links persist over time. We can maka a bipartite \"network\" of books and nodes, and books and edges, and easily see their presence trough time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc525050-c847-4857-a0d5-22660d98b733",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"><b>Up to you: </b>\n",
    "<h4> Exercise 25</h4>\n",
    "    \n",
    "Create a bipartite network of books and interactions. In that network the nodes in one set are the different books, while the nodes in the second set are the interactions between the characters.\n",
    "These types of networks are used, for example, to study how ecological interactions are structured in different fields.\n",
    "    \n",
    "- 1.  How many interactions characters are shared between the first and the second book?\n",
    "- 2.  What books share the most number of character interactions?\n",
    "    \n",
    "Create a bipartite network of books and characters. In that network the nodes in one set are the different books, while the nodes in the second set are the characters.\n",
    "- 3. What books share the most number of characters?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6293d645-fc97-46dd-8bf4-7c1551098ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5ce45a-ea53-46cf-9da2-96026d60c652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./snippets/ex25.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c3ec05-573f-4cac-a9fc-fbe2ffc2168a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./snippets/ex25b.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015a7e68-5569-4112-8ed9-8e9e824d0feb",
   "metadata": {},
   "source": [
    "## Air traffic\n",
    "we will analyse the evolution of US Airport Network between 1990 and 2015. This dataset contains data for 25 years[1995-2015] of flights between various US airports and metadata about these routes. Taken from Bureau of Transportation Statistics, United States Department of Transportati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558cb03c-8d5f-400e-86e3-7c8ced7d1bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_airports_data():\n",
    "    pass_air_data = pd.read_csv(\"./data/passengers.csv\", index_col=\"id\")\n",
    "    return pass_air_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c92ab44-cfa3-48dd-bc3f-98eae10793b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_air_data=load_airports_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1764b3b-5736-43b2-968a-6f4412a726b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_air_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1f240e-ec92-40bb-9b85-ec2ed94db7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "passenger_graph = nx.from_pandas_edgelist(\n",
    "    pass_air_data, source='ORIGIN',\n",
    "    target='DEST', edge_key='YEAR',\n",
    "    edge_attr=['PASSENGERS', 'UNIQUE_CARRIER_NAME'],\n",
    "    create_using=nx.MultiDiGraph())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4faa1b-0c6c-4765-8b67-63e737f181e5",
   "metadata": {},
   "source": [
    "We have created a MultiDiGraph object `passenger_graph` which contains all the information from the dataframe `pass_air_data`. `ORIGIN` and `DEST` represent the column names in the dataframe `pass_air_data` used to construct the edge. As this is a `MultiDiGraph` we can also give a name/key to the multiple edges between two nodes and `edge_key` is used to represent that name and in this graph `YEAR` is used to distinguish between multiple edges between two nodes. `PASSENGERS` and `UNIQUE_CARRIER_NAME` are added as edge attributes which can be accessed using the nodes and the key form the MultiDiGraph object.\n",
    "\n",
    "Let's check if can access the same information (the 2006 route between JFK and AUS) using our `passenger_graph`.\n",
    "\n",
    "To check an edge between two nodes in a Graph we can use the syntax `GraphObject[source][target]` and further specify the edge attribute using `GraphObject[source][target][attribute]`.\n",
    "\n",
    "<!-- Let's see if `passenger_graph['JFK']['AUS'][2006]` works. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ca71b6-36a9-410e-a106-09818d17fa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "passenger_graph['JFK']['AUS'][2006]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a281eea-3cb4-4813-b993-34c05abdf2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Route betweeen New York-JFK and SFO\n",
    "\n",
    "values = [(year, attr['PASSENGERS'])\n",
    "          for year, attr in \n",
    "          passenger_graph['JFK']['SFO'].items()]\n",
    "x, y = zip(*values)\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720347c3-5faf-4d76-be53-224edd9bb8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_air_data.groupby(\n",
    "    ['YEAR']).sum()['PASSENGERS'].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204aaaf1-4dfb-496b-a312-023181590bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_network(G, year):\n",
    "    \"\"\" Extract edges for a particular year from\n",
    "        a MultiGraph. The edge is also populated with\n",
    "        two attributes, weight and weight_inv where\n",
    "        weight is the number of passengers and\n",
    "        weight_inv the inverse of it.\n",
    "    \"\"\"\n",
    "    year_network = nx.DiGraph()\n",
    "    for edge in G.edges:\n",
    "        source, target, edge_year = edge\n",
    "        if edge_year == year:\n",
    "            attr = G[source][target][edge_year]\n",
    "            year_network.add_edge(\n",
    "                source, target,\n",
    "                weight=attr['PASSENGERS'],\n",
    "                weight_inv=1/(attr['PASSENGERS']\n",
    "                if attr['PASSENGERS'] != 0.0 else 1),\n",
    "                airlines=attr['UNIQUE_CARRIER_NAME'])\n",
    "    return year_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5404a568-94b3-4474-9f50-3f7bbdd5c20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_2015_network = year_network(passenger_graph, 2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac810dd-c63b-40c9-9afe-b5141f69a4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_2015_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54407d1d-cfae-4150-8eca-50b39b75c85a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "net-course",
   "language": "python",
   "name": "net-course"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
